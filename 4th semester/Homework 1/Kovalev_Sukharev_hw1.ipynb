{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1. Сравнение стилей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работу выполнили Ковалев Евгений и Сухарев Иван, 4 группа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном домашнем задании мы проверяли гипотезу о различии характеров распределений частот частей речи в текстах разных стилей. Для \n",
    "этого мы составили коллекции текстов официально-делового, публицистического, разговорного и художественного стилей. Далее с помощью \n",
    "морфологического процессора из библиотеки pymorphy2 мы определили части речи, к которым относятся слова из каждой коллекции, и \n",
    "составили для них частотные словари. Затем для каждой пары наборов частот был посчитан коэффициент корреляции Спирмена. Исходя из результатов, можно сделать вывод, что гипотеза не подтверждается, потому что корреляция между частотными словарями для разных стилей текстов достаточно высокая. Следует заметить, что полученные значения коэффициентов корреляции отличаются друг от друга, и, например, официально-деловой стиль больше похож на публицистический, чем на художественный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание коллекций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[2 балла] Составьте самостоятельно как минимум две коллекции\n",
    "текстов разных стилей (например, коллекция текстов в публицистическом\n",
    "стиле и коллекция текстов в научном стиле). Коллекции текстов\n",
    "должны быть достаточно большие (порядка 5000 токенов). Посчитайте\n",
    "количество токенов и типов в каждой коллекции.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pandas as pd\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим сортировку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = set(punctuation + '0123456789'+u'–—'+u'«»')\n",
    "def tokenization(collection):\n",
    "    tokens = WhitespaceTokenizer().tokenize(collection.lower())\n",
    "    types = nltk.FreqDist(tokens)\n",
    "    return tokens, types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём коллекции из текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_collection_with_range(style, ran):\n",
    "    texts = []\n",
    "    for file in sorted(glob.glob(style + '\\\\*.txt'), key=numericalSort):\n",
    "        texts.append(file)\n",
    "    collection = []\n",
    "    for i in range(ran):\n",
    "        lines = open(texts[i]).readlines()\n",
    "        collection.append(' '.join(''.join(lines).replace('\\n', ' ').split()))\n",
    "    collection = ' '.join(collection)\n",
    "    collection = ''.join(ch for ch in collection if ch not in exclude)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colloquial = create_collection_with_range('colloquial', 15)\n",
    "publicistic = create_collection_with_range('publicistic', 15)\n",
    "art = create_collection_with_range('art', 5)\n",
    "official = create_collection_with_range('official', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделяем токены и типы, считаем их количество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colloquial_tokens, colloquial_types = tokenization(colloquial)\n",
    "publicistic_tokens, publicistic_types = tokenization(publicistic)\n",
    "art_tokens, art_types = tokenization(art)\n",
    "official_tokens, official_types = tokenization(official)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens (colloquial):  16756\n",
      "number of types (colloquial): 6039\n",
      "number of tokens (publicistic):  6753\n",
      "number of types (publicistic): 3048\n",
      "number of tokens (art):  16953\n",
      "number of types (art): 5694\n",
      "number of tokens (official):  15363\n",
      "number of types (official): 4712\n"
     ]
    }
   ],
   "source": [
    "print('number of tokens (colloquial): ', len(colloquial_tokens))\n",
    "print('number of types (colloquial):', len(colloquial_types))\n",
    "print('number of tokens (publicistic): ', len(publicistic_tokens))\n",
    "print('number of types (publicistic):', len(publicistic_types))\n",
    "print('number of tokens (art): ', len(art_tokens))\n",
    "print('number of types (art):', len(art_types))\n",
    "print('number of tokens (official): ', len(official_tokens))\n",
    "print('number of types (official):', len(official_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение частей речи и составление частотных словарей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[5 баллов] Используя любой морфологический процессор, который\n",
    "вам нравится (pymorphy2, mystem), определите к какой части речи\n",
    "относятся слова из каждой коллекции текстов. При помощи nltk.FreqDist()\n",
    "составьте частотные словари: часть речи – количество слов, к ней\n",
    "относящихся.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составляем частотные словари."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "def morphanalysis(collection):\n",
    "    tags = []\n",
    "    for word in collection.split():\n",
    "        tags.append(morph.parse(word)[0].tag.POS)\n",
    "    tags_dict = nltk.FreqDist(tags)\n",
    "    return tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colloquial_tags = morphanalysis(colloquial)\n",
    "publicistic_tags = morphanalysis(publicistic)\n",
    "art_tags = morphanalysis(art)\n",
    "official_tags = morphanalysis(official)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем частоты частей речи в порядке убывания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colloquial:\n",
      "NOUN 4178\n",
      "ADJF 2077\n",
      "CONJ 1915\n",
      "VERB 1854\n",
      "PREP 1821\n",
      "NPRO 1252\n",
      "ADVB 1099\n",
      "PRCL 1030\n",
      "INFN 660\n",
      "ADJS 185\n",
      "None 124\n",
      "PRTS 112\n",
      "PRTF 110\n",
      "PRED 106\n",
      "COMP 98\n",
      "GRND 58\n",
      "INTJ 49\n",
      "NUMR 28\n"
     ]
    }
   ],
   "source": [
    "print('Colloquial:')\n",
    "for i in sorted(colloquial_tags, key=colloquial_tags.get, reverse=True):\n",
    "    print(i, colloquial_tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publicistic:\n",
      "NOUN 2960\n",
      "PREP 1022\n",
      "ADJF 724\n",
      "VERB 661\n",
      "CONJ 339\n",
      "ADVB 209\n",
      "PRCL 162\n",
      "INFN 136\n",
      "NPRO 133\n",
      "None 114\n",
      "PRTF 80\n",
      "NUMR 56\n",
      "ADJS 51\n",
      "PRTS 50\n",
      "GRND 19\n",
      "COMP 14\n",
      "PRED 13\n",
      "INTJ 10\n"
     ]
    }
   ],
   "source": [
    "print('Publicistic:')\n",
    "for i in sorted(publicistic_tags, key=publicistic_tags.get, reverse=True):\n",
    "    print(i, publicistic_tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art:\n",
      "NOUN 4243\n",
      "VERB 2305\n",
      "CONJ 1942\n",
      "PREP 1608\n",
      "ADJF 1587\n",
      "NPRO 1433\n",
      "ADVB 1234\n",
      "PRCL 977\n",
      "INFN 417\n",
      "GRND 261\n",
      "None 211\n",
      "PRTF 173\n",
      "ADJS 167\n",
      "PRED 102\n",
      "NUMR 86\n",
      "INTJ 71\n",
      "COMP 69\n",
      "PRTS 67\n"
     ]
    }
   ],
   "source": [
    "print('Art:')\n",
    "for i in sorted(art_tags, key=art_tags.get, reverse=True):\n",
    "    print(i, art_tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official:\n",
      "NOUN 6771\n",
      "ADJF 2752\n",
      "PREP 2017\n",
      "CONJ 1201\n",
      "VERB 697\n",
      "PRTF 423\n",
      "ADVB 300\n",
      "INFN 279\n",
      "PRCL 241\n",
      "NPRO 212\n",
      "None 184\n",
      "PRTS 103\n",
      "ADJS 59\n",
      "NUMR 53\n",
      "PRED 33\n",
      "INTJ 14\n",
      "COMP 12\n",
      "GRND 12\n"
     ]
    }
   ],
   "source": [
    "print('Official:')\n",
    "for i in sorted(official_tags, key=official_tags.get, reverse=True):\n",
    "    print(i, official_tags[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляции Спирмена"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[3 балла] Посчитайте коэффициент корреляции Спирмена для\n",
    "полученных на предыдущем шаге частот частей речи. На основании\n",
    "полученного значения, сделайте вывод: подтверждается ли гипотеза,\n",
    "сформулированная в задании? Если вы рассматривали больше\n",
    "двух стилей, можно ли утверждать, что один стиль больше похож\n",
    "на второй, чем на третий?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства вывода загрузим данные в pandas и воспользуемся встроенной функцией corr()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Art</th>\n",
       "      <th>Offic</th>\n",
       "      <th>Colloq</th>\n",
       "      <th>Public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Art</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826020</td>\n",
       "      <td>0.886481</td>\n",
       "      <td>0.902993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Offic</th>\n",
       "      <td>0.826020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887971</td>\n",
       "      <td>0.937532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colloq</th>\n",
       "      <td>0.886481</td>\n",
       "      <td>0.887971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public</th>\n",
       "      <td>0.902993</td>\n",
       "      <td>0.937532</td>\n",
       "      <td>0.905057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Art     Offic    Colloq    Public\n",
       "Art     1.000000  0.826020  0.886481  0.902993\n",
       "Offic   0.826020  1.000000  0.887971  0.937532\n",
       "Colloq  0.886481  0.887971  1.000000  0.905057\n",
       "Public  0.902993  0.937532  0.905057  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTags = list(set(colloquial_tags))\n",
    "tags = [art_tags, official_tags, colloquial_tags, publicistic_tags]\n",
    "vals = []\n",
    "for i in range(4):\n",
    "    newList = []\n",
    "    for name in listOfTags:\n",
    "        newList.append(tags[i][name])\n",
    "    vals.append(newList)\n",
    "    \n",
    "df = pd.DataFrame(data=vals).T\n",
    "df.columns = ['Art', 'Offic', 'Colloq', 'Public']\n",
    "df.corr('spearman')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
